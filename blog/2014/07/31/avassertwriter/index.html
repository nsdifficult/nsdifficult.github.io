
<!DOCTYPE HTML>
<html>
<head>
	<meta charset="utf-8">
	<title>使用AVAssertWriter录制音视频到文件 - RONGYI.WORK</title>
	<meta name="author" content="易荣义">

	
	<meta name="description" content="今天写直播功能中的录制视频到文件时使用AVAssertWriter遇到一个坑。 1
2
3
4
5
6
7 if ([assetWriter canAddInput:assetWriterAudioIn]) { [assetWriter addInput:assetWriterAudioIn]; &hellip;">
	
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<link href="/atom.xml" rel="alternate" title="RONGYI.WORK" type="application/atom+xml">
	<link rel="canonical" href="">
	<link href="/favicon.png" rel="shortcut icon">
	<link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
	<!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
	<script async="true" src="http://libs.useso.com/js/jquery/1.7.2/jquery.min.js"></script>
	
</head>


<body>
	<header id="header" class="inner"><h1><a href="/">RONGYI.WORK</a></h1>
<nav id="main-nav"><ul class="main">
	<li><a href="/">主页</a></li>
	<li><a href="/blog/archives">所有文章</a></li>
</ul>
</nav>
<nav id="mobile-nav">
	<div class="alignleft menu">
		<a class="button">Menu</a>
		<div class="container"><ul class="main">
	<li><a href="/">主页</a></li>
	<li><a href="/blog/archives">所有文章</a></li>
</ul>
</div>
	</div>
	<div class="alignright search">
		<a class="button"></a>
		<div class="container">
			<form action="https://www.google.com/search" method="get">
				<input type="text" name="q" results="0">
				<input type="hidden" name="q" value="site:rongyi.work">
			</form>
		</div>
	</div>
</nav>
<nav id="sub-nav" class="alignright">
	<div class="social">
		
		
		
		
    
		
		
		
		
		
		<a class="rss" href="/atom.xml" title="RSS">RSS</a>
		
    
	</div>
	<form class="search" action="https://www.google.com/search" method="get">
		<input class="alignright" type="text" name="q" results="0">
		<input type="hidden" name="q" value="site:rongyi.work">
	</form>
</nav>

</header>
	
		
	
	<div id="content" class="inner"><article class="post">
	<h2 class="title">使用AVAssertWriter录制音视频到文件</h2>
	<div class="entry-content"><p>今天写直播功能中的录制视频到文件时使用AVAssertWriter遇到一个坑。<!--more--></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> if ([assetWriter canAddInput:assetWriterAudioIn]) {
</span><span class='line'>      [assetWriter addInput:assetWriterAudioIn];
</span><span class='line'>        NSLog(@"add asset writer audio input.");
</span><span class='line'>  } else {
</span><span class='line'>        NSLog(@"Couldn't add asset writer audio input.");
</span><span class='line'>        return NO;
</span><span class='line'>  }</span></code></pre></td></tr></table></div></figure>


<p>这句话总是报<code>Couldn't add asset writer audio input.</code></p>

<p>后来不判断直接调用<code>[assetWriter addInput:assetWriterAudioIn];</code>发现报错：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[AVAssetWriter addInput:] Cannot call method when status is 1</span></code></pre></td></tr></table></div></figure>


<p>发现AVAssetWriter的status为1时，是为AVAssetWriterStatusWriting。即AVAssetWriter正在写。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>enum {
</span><span class='line'>   AVAssetWriterStatusUnknown = 0,
</span><span class='line'>   AVAssetWriterStatusWriting,
</span><span class='line'>   AVAssetWriterStatusCompleted,
</span><span class='line'>   AVAssetWriterStatusFailed,
</span><span class='line'>   AVAssetWriterStatusCancelled
</span><span class='line'>};
</span><span class='line'>typedef NSInteger AVAssetWriterStatus;</span></code></pre></td></tr></table></div></figure>


<p>就是说AVAssetWriter已经在写文件了，不能在它写文件的时候加入assetWriterAudioIn。这个问题可真够隐蔽的，而且官方文档没有任何这方面的提醒，鄙视下==</p>

<p>解决这个问题的一个关键步骤是直接调用<code>[assetWriter addInput:assetWriterAudioIn];</code></p>

<p>最后贴上代码：</p>

<p>首先初始化相机、AVCaptureVideoDataOutput、AVCaptureAudioDataOutput等：</p>

<pre><code>void  CameraSource::setupCamera(int fps, bool useFront, bool useInterfaceOrientation)
    {
    m_fps = fps;
    m_useInterfaceOrientation = useInterfaceOrientation;


    @autoreleasepool {
        int position = useFront ? AVCaptureDevicePositionFront : AVCaptureDevicePositionBack;

        NSArray* devices = [AVCaptureDevice devices];
        for(AVCaptureDevice* d in devices) {
            if([d hasMediaType:AVMediaTypeVideo] &amp;&amp; [d position] == position)
            {
                m_captureDevice = d;
                NSError* error;
                [d lockForConfiguration:&amp;error];
                [d setActiveVideoMinFrameDuration:CMTimeMake(1, fps)];
                [d setActiveVideoMaxFrameDuration:CMTimeMake(1, fps)];
                [d unlockForConfiguration];
            }
        }

        AVCaptureSession* session = [[AVCaptureSession alloc] init];
        AVCaptureDeviceInput* input;
        AVCaptureVideoDataOutput* output;

        NSString* preset = AVCaptureSessionPresetHigh;
        if(m_usingDeprecatedMethods) {
            int mult = ceil(double(m_targetSize.h) / 270.0) * 270 ;
            switch(mult) {
                case 270:
                    preset = AVCaptureSessionPresetLow;
                    break;
                case 540:
                    preset = AVCaptureSessionPresetMedium;
                    break;
                default:
                    preset = AVCaptureSessionPresetHigh;
                    break;
            }
            session.sessionPreset = preset;
        }
        m_captureSession = session;

        input = [AVCaptureDeviceInput deviceInputWithDevice:((AVCaptureDevice*)m_captureDevice) error:nil];

        output = [[AVCaptureVideoDataOutput alloc] init] ;

        output.videoSettings = @{(NSString*)kCVPixelBufferPixelFormatTypeKey: @(kCVPixelFormatType_32BGRA) };
        if(!m_callbackSession) {
            m_callbackSession = [[sbCallback alloc] init];
        }

        /***音频 begin*/
        /*
         * Create audio connection
         */
        NSArray *audioDevices = [AVCaptureDevice devicesWithMediaType:AVMediaTypeAudio];
        AVCaptureDevice *audioDevice;
        if ([audioDevices count] &gt; 0) {
            audioDevice = [audioDevices objectAtIndex:0];
            AVCaptureDeviceInput *audioIn = [[AVCaptureDeviceInput alloc] initWithDevice:audioDevice error:nil];
            if ([session canAddInput:audioIn])
                [session addInput:audioIn];
            [audioIn release];

            AVCaptureAudioDataOutput *audioOut = [[AVCaptureAudioDataOutput alloc] init];
            dispatch_queue_t audioCaptureQueue = dispatch_queue_create("PHONELIVE_AUDIO_QUEUE", DISPATCH_QUEUE_SERIAL);
            [audioOut setSampleBufferDelegate:((sbCallback *)m_callbackSession) queue:audioCaptureQueue];
            dispatch_release(audioCaptureQueue);
            if ([session canAddOutput:audioOut]) {
                [session addOutput:audioOut];
                audioConnection = [audioOut connectionWithMediaType:AVMediaTypeAudio];
            }
            [audioOut release];
        }


        /***音频 end*/

        //当sampleBufferDelegate处理frame时，queue被blocked，新来的frame不处理。为YES时保存，不blocked时处理，这样占用的内存多。
        [output setAlwaysDiscardsLateVideoFrames:YES];
        videoDataOutputQueue = dispatch_queue_create("PHONELIVE_VIDEO_QUEUE", DISPATCH_QUEUE_SERIAL);
        //            [output setSampleBufferDelegate:((sbCallback*)m_callbackSession) queue:dispatch_get_global_queue(0, 0)];
        [output setSampleBufferDelegate:((sbCallback*)m_callbackSession) queue:videoDataOutputQueue];
        dispatch_release(videoDataOutputQueue);
        if([session canAddInput:input]) {
            [session addInput:input];
        }
        if([session canAddOutput:output]) {
            [session addOutput:output];
            videoConnection = [output connectionWithMediaType:AVMediaTypeVideo];

        }

        movieWritingQueue = dispatch_queue_create("PHONELIVE_WRITING_QUEUE", DISPATCH_QUEUE_SERIAL);

        reorientCamera();

        [session startRunning];

        if(m_useInterfaceOrientation) {
            [[NSNotificationCenter defaultCenter] addObserver:((id)m_callbackSession) selector:@selector(orientationChanged:) name:UIApplicationDidChangeStatusBarOrientationNotification object:nil];
        } else {
            [[UIDevice currentDevice] beginGeneratingDeviceOrientationNotifications];
            [[NSNotificationCenter defaultCenter] addObserver:((id)m_callbackSession) selector:@selector(orientationChanged:) name:UIDeviceOrientationDidChangeNotification object:nil];
        }
        [output release];

    }
}
</code></pre>

<p>在didOutputSampleBuffer初始化AVAssertWriter和写文件</p>

<pre><code>- (void)captureOutput:(AVCaptureOutput *)captureOutput didOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer
   fromConnection:(AVCaptureConnection *)connection
{
auto source = m_source.lock();

if(source) {
    if (connection == source-&gt;videoConnection) {
        source-&gt;bufferCaptured(CMSampleBufferGetImageBuffer(sampleBuffer));
        if (source-&gt;m_isFisrtToUseCamera) {
            source-&gt;m_cameraHasBeingPreparedCallback();
            source-&gt;m_isFisrtToUseCamera = false;
        }
    }

    if (source-&gt;readyToRecordVideo&amp;&amp;source-&gt;readyToRecordAudio) {

        CMFormatDescriptionRef formatDescription = CMSampleBufferGetFormatDescription(sampleBuffer);

        CFRetain(sampleBuffer);
        CFRetain(formatDescription);

        dispatch_async(source-&gt;movieWritingQueue, ^{
            if (connection == source-&gt;videoConnection) {
                if (!source-&gt;m_isRecordingVideo) {
                    // Initialize the video input if this is not done yet
                    source-&gt;m_isRecordingVideo = source-&gt;setupAssetWriterVideoInput(formatDescription);
                }
                if (source-&gt;m_isRecordingVideo &amp;&amp; source-&gt;m_isRecordingAudio) {
                    source-&gt;writeSampleBuffer(sampleBuffer,AVMediaTypeVideo);
                }
            } else if (connection == source-&gt;audioConnection) {
                if (!source-&gt;m_isRecordingAudio) {
                    // Initialize the video input if this is not done yet
                    source-&gt;m_isRecordingAudio = source-&gt;setupAssetWriterAudioInput(formatDescription);
                }
                if (source-&gt;m_isRecordingVideo &amp;&amp; source-&gt;m_isRecordingAudio) {
                    source-&gt;writeSampleBuffer(sampleBuffer,AVMediaTypeAudio);
                }
            }


            CFRelease(sampleBuffer);
            CFRelease(formatDescription);

        });

    }
}
}
</code></pre>

<p>注意，解决我遇到的坑是这句:<code>if (source-&gt;m_isRecordingVideo &amp;&amp; source-&gt;m_isRecordingAudio)</code>，即设置两个变量标识AVAssertWriter是否加入AVCaptureVideoDataOutput和AVCaptureAudioDataOutput，在加入后才开始写文件。</p>

<p>最后AVAssertWriter加入AVCaptureVideoDataOutput和AVCaptureAudioDataOutput、写文件的方法：</p>

<pre><code>BOOL
CameraSource::setupAssetWriterVideoInput(CMFormatDescriptionRef currentFormatDescription)
{
    float bitsPerPixel;
    CMVideoDimensions dimensions = CMVideoFormatDescriptionGetDimensions(currentFormatDescription);
    int numPixels = dimensions.width * dimensions.height;
    int bitsPerSecond;

    // Assume that lower-than-SD resolutions are intended for streaming, and use a lower bitrate
    if ( numPixels &lt; (640 * 480) ) {
        bitsPerPixel = 4.05; // This bitrate matches the quality produced by AVCaptureSessionPresetMedium or Low.
    } else {
        bitsPerPixel = 11.4; // This bitrate matches the quality produced by AVCaptureSessionPresetHigh.

        bitsPerSecond = numPixels * bitsPerPixel;

        NSDictionary *videoCompressionSettings = [NSDictionary dictionaryWithObjectsAndKeys:
                                                  AVVideoCodecH264, AVVideoCodecKey,
                                                  [NSNumber numberWithFloat:[UIScreen mainScreen].bounds.size.height*[UIScreen mainScreen].scale], AVVideoWidthKey,
                                                  [NSNumber numberWithFloat:[UIScreen mainScreen].bounds.size.width*[UIScreen mainScreen].scale], AVVideoHeightKey,
                                                  [NSDictionary dictionaryWithObjectsAndKeys:
                                                   [NSNumber numberWithInteger:1000000], AVVideoAverageBitRateKey,
                                                   [NSNumber numberWithInteger:30], AVVideoMaxKeyFrameIntervalKey,
                                                   nil], AVVideoCompressionPropertiesKey,
                                                  nil];

        if ([assetWriter canApplyOutputSettings:videoCompressionSettings forMediaType:AVMediaTypeVideo]) {
            assetWriterVideoIn = [[AVAssetWriterInput alloc] initWithMediaType:AVMediaTypeVideo outputSettings:videoCompressionSettings];
            assetWriterVideoIn.expectsMediaDataInRealTime = YES;
            //                assetWriterVideoIn.transform = [self transformFromCurrentVideoOrientationToOrientation:self.referenceOrientation];
            [assetWriter addInput:assetWriterVideoIn];
            if ([assetWriter canAddInput:assetWriterVideoIn]) {
                [assetWriter addInput:assetWriterVideoIn];
                NSLog(@"add asset writer video input.");
            } else {
                NSLog(@"Couldn't add asset writer video input.");
                return NO;
            }
        } else {
            NSLog(@"Couldn't apply video output settings.");
            return NO;
        }
    }
    return YES;
}

BOOL
CameraSource::setupAssetWriterAudioInput(CMFormatDescriptionRef currentFormatDescription)
{
    const AudioStreamBasicDescription *currentASBD = CMAudioFormatDescriptionGetStreamBasicDescription(currentFormatDescription);

    size_t aclSize = 0;
    const AudioChannelLayout *currentChannelLayout = CMAudioFormatDescriptionGetChannelLayout(currentFormatDescription, &amp;aclSize);
    NSData *currentChannelLayoutData = nil;

    // AVChannelLayoutKey must be specified, but if we don't know any better give an empty data and let AVAssetWriter decide.
    if ( currentChannelLayout &amp;&amp; aclSize &gt; 0 )
        currentChannelLayoutData = [NSData dataWithBytes:currentChannelLayout length:aclSize];
    else
        currentChannelLayoutData = [NSData data];

    NSDictionary *audioCompressionSettings = [NSDictionary dictionaryWithObjectsAndKeys:
                                              [NSNumber numberWithInteger:kAudioFormatMPEG4AAC], AVFormatIDKey,
                                              [NSNumber numberWithFloat:currentASBD-&gt;mSampleRate], AVSampleRateKey,
                                              [NSNumber numberWithInt:64000], AVEncoderBitRatePerChannelKey,
                                              [NSNumber numberWithInteger:currentASBD-&gt;mChannelsPerFrame], AVNumberOfChannelsKey,
                                              currentChannelLayoutData, AVChannelLayoutKey,
                                              nil];
    if ([assetWriter canApplyOutputSettings:audioCompressionSettings forMediaType:AVMediaTypeAudio]) {

        assetWriterAudioIn = [[AVAssetWriterInput alloc] initWithMediaType:AVMediaTypeAudio outputSettings:audioCompressionSettings];
        assetWriterAudioIn.expectsMediaDataInRealTime = YES;
        if ([assetWriter canAddInput:assetWriterAudioIn]) {
            [assetWriter addInput:assetWriterAudioIn];
            NSLog(@"add asset writer audio input.");
        } else {
            NSLog(@"Couldn't add asset writer audio input.");
            return NO;
        }
    }
    else {
        NSLog(@"Couldn't apply audio output settings.");
        return NO;
    }

    return YES;
}
void
CameraSource::writeSampleBuffer(CMSampleBufferRef sampleBuffer,NSString *mediaType) {
    if ( assetWriter.status == AVAssetWriterStatusUnknown ) {

        if ([assetWriter startWriting]) {
            CMTime lastSampleTime = CMSampleBufferGetPresentationTimeStamp(sampleBuffer);
            [assetWriter startSessionAtSourceTime:lastSampleTime];
        }
        else {
            //                [self showError:[assetWriter error]];
            NSLog(@"%@",assetWriter.error);

        }
    }

    if ( assetWriter.status == AVAssetWriterStatusWriting ) {

        if (mediaType == AVMediaTypeVideo) {
            if (assetWriterVideoIn.readyForMoreMediaData) {
                if (![assetWriterVideoIn appendSampleBuffer:sampleBuffer]) {
                    //                        [self showError:[assetWriter error]];
                    NSLog(@"%@",assetWriter.error);
                }
            }
        }else if (mediaType == AVMediaTypeAudio) {
            if (assetWriterAudioIn.readyForMoreMediaData) {
                if (![assetWriterAudioIn appendSampleBuffer:sampleBuffer]) {
                    //                        [self showError:[assetWriter error]];
                    NSLog(@"%@",assetWriter.error);

                }
            }
        }
    }
}
</code></pre>

<p>参考：<br/>
1. <a href="https://developer.apple.com/library/ios/documentation/AudioVideo/Conceptual/AVFoundationPG/Articles/05_Export.html#//apple_ref/doc/uid/TP40010188-CH9-SW2">AV Foundation Programming Guide</a><br/>
2. <a href="https://developer.apple.com/library/ios/samplecode/RosyWriter/Introduction/Intro.html">官方demo：RosyWriter</a></p>
</div>


<div class="meta">
	<div class="date">




Jul 31st, 2014</div>
	<div class="tags">

</div>
	
</div>
</article>

	<div class="share">
	<div class="addthis_toolbox addthis_default_style ">
		
		
		
		
	</div>
	
</div>




  <section>
    <h1>评论</h1>
    <div id="comments" aria-live="polite"><!-- 多说评论框 start -->
<div class="ds-thread" data-thread-key="/blog/2014/07/31/avassertwriter" data-title="使用AVAssertWriter录制音视频到文件" data-url="http://rongyi.work/blog/2014/07/31/avassertwriter/"></div>
<!-- 多说评论框 end -->
<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
<script type="text/javascript">
    var duoshuoQuery = {short_name:"24yi"};
    (function() {

        var ds = document.createElement('script');
        ds.type = 'text/javascript';ds.async = true;
        ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
        ds.charset = 'UTF-8';
        (document.getElementsByTagName('head')[0]
         || document.getElementsByTagName('body')[0]).appendChild(ds);
     })();
 </script>
 <!-- 多说公共JS代码 end -->
</div>
  </section>
</div>
	<footer id="footer" class="inner">Copyright &copy; 2016

    易荣义

</footer>
	<script src="/javascripts/slash.js"></script>
<script src="/javascripts/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
	$('.fancybox').fancybox();
})(jQuery);
</script> <!-- Delete or comment this line to disable Fancybox -->






</body>
</html>